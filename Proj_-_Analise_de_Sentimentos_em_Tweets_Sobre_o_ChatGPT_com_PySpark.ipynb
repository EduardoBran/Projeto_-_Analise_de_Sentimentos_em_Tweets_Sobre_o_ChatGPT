{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "990a67d4",
   "metadata": {},
   "source": [
    "<span style=\"color: green; font-size: 40px; font-weight: bold;\">Projeto 2 (Análise de Sentimentos)</span>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "# Análise de Sentimentos sobre o ChatGPT no Twitter\n",
    "\n",
    "<br>\n",
    "\n",
    "### Contexto\n",
    "\n",
    "Este projeto explora a **análise de sentimentos de tweets sobre o ChatGPT** para entender como o público está reagindo a essa nova tecnologia. Desde o lançamento do ChatGPT, as opiniões estão divididas, com alguns elogiando seu potencial enquanto outros demonstram receio em relação à substituição de empregos e outros aspectos sociais. A análise de sentimentos é uma ferramenta importante para medir essas reações. Este projeto utilizará o PySpark para processar e analisar grandes volumes de dados de tweets e identificar o sentimento predominante (positivo, negativo ou neutro) em relação ao ChatGPT.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Objetivo\n",
    "\n",
    "O objetivo deste projeto é **analisar os sentimentos dos usuários no Twitter em relação ao ChatGPT**. Utilizando dados estáticos coletados de tweets, o modelo irá identificar se a opinião prevalente sobre o ChatGPT é positiva, negativa ou neutra. Embora não seja obrigatório usar `Machine Learning`, isso pode ser uma opção dependendo da necessidade.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Pergunta de Negócio Principal\n",
    "\n",
    "> \"**Qual é o sentimento predominante nas redes sociais, especificamente no Twitter, sobre o ChatGPT?**\"\n",
    "\n",
    "<br>\n",
    "\n",
    "### Entregável\n",
    "\n",
    "O entregável será **duas formas de análise de sentimentos dos tweets sobre o ChatGPT**:\n",
    "\n",
    "- **1. Análise utilizando a biblioteca VADER**, que se baseia em uma abordagem baseada em regras para classificar os tweets como positivos, negativos ou neutros.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **2.Análise utilizando Machine Learning**, que envolve o uso de um modelo treinado para prever o sentimento dos tweets com base em dados rotulados.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Cada abordagem será desenvolvida de maneira independente, permitindo comparar os resultados entre a análise baseada em regras e o modelo treinado.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Sobre o Conjunto de Dados\n",
    "\n",
    "Os `dados estáticos utilizados neste projeto foram coletados a partir de um conjunto de dados do Kaggle`, que contém **50.001 tweets** sobre o ChatGPT. As colunas principais de interesse incluem o conteúdo do tweet, o idioma, e informações sobre interações como retweets, likes, e respostas. O **conteúdo textual (coluna \"Text\")** será a principal variável para a análise de sentimentos.\n",
    "\n",
    "<br> <table border=\"2\"> <tr> <th style=\"text-align: center; font-size: 16px;\">Nome da Coluna</th> <th style=\"text-align: center; font-size: 16px;\">Tipo de Dado</th> <th style=\"text-align: center; font-size: 16px;\">Descrição</th> </tr> <tr> <td>Datetime</td> <td>object</td> <td>Data e hora do tweet.</td> </tr> <tr> <td>Tweet Id</td> <td>int64</td> <td>ID único do tweet.</td> </tr> <tr> <td>Text</td> <td>object</td> <td>Conteúdo textual do tweet.</td> </tr> <tr> <td>Username</td> <td>object</td> <td>Nome de usuário do autor do tweet.</td> </tr> <tr> <td>Permalink</td> <td>object</td> <td>Link direto para o tweet.</td> </tr> <tr> <td>User</td> <td>object</td> <td>URL do perfil do autor do tweet.</td> </tr> <tr> <td>Outlinks</td> <td>object</td> <td>Links incluídos no tweet.</td> </tr> <tr> <td>CountLinks</td> <td>object</td> <td>Contagem de links no tweet.</td> </tr> <tr> <td>ReplyCount</td> <td>int64</td> <td>Número de respostas ao tweet.</td> </tr> <tr> <td>RetweetCount</td> <td>int64</td> <td>Número de retweets.</td> </tr> <tr> <td>LikeCount</td> <td>int64</td> <td>Número de likes no tweet.</td> </tr> <tr> <td>QuoteCount</td> <td>int64</td> <td>Número de vezes que o tweet foi citado.</td> </tr> <tr> <td>ConversationId</td> <td>int64</td> <td>ID da conversa relacionada ao tweet.</td> </tr> <tr> <td>Language</td> <td>object</td> <td>Idioma do tweet.</td> </tr> <tr> <td>Source</td> <td>object</td> <td>Fonte de onde o tweet foi enviado (ex: iPhone, Android).</td> </tr> <tr> <td>Media</td> <td>object</td> <td>Mídias associadas ao tweet (imagens, vídeos).</td> </tr> <tr> <td>QuotedTweet</td> <td>object</td> <td>Informações sobre o tweet citado (se houver).</td> </tr> <tr> <td>MentionedUsers</td> <td>object</td> <td>Usuários mencionados no tweet.</td> </tr> <tr> <td>hashtag</td> <td>object</td> <td>Hashtags usadas no tweet.</td> </tr> <tr> <td>hastag_counts</td> <td>int64</td> <td>Contagem de hashtags no tweet.</td> </tr> </table>\n",
    "\n",
    "<br><br><br><br>\n",
    "\n",
    "# Instruções para Execução do Projeto\n",
    "\n",
    "<br><br>\n",
    "\n",
    "## Parte 1: Análise de Sentimento com VADER\n",
    "\n",
    "#### 1. Carregamento do Dataset\n",
    "\n",
    "- **Carregamento dos Dados**: O primeiro passo é carregar o dataset de tweets utilizando o PySpark.\n",
    "- **Exploração dos Dados**: Após o carregamento, será realizada uma análise exploratória inicial para entender a estrutura dos dados, verificar a presença de valores ausentes, linhas duplicadas e identificar possíveis caracteres especiais nas colunas de texto.\n",
    "\n",
    "#### 2. Limpeza e Manipulação dos Dados:\n",
    "\n",
    "- **Filtragem e Seleção de Colunas**: O DataFrame será filtrado para manter apenas os tweets escritos em **inglês**. Serão selecionadas algumas outras colunas para salvar no dataframe assim como `Text`.\n",
    "- **Limpeza e Normalização dos Textos**: A coluna `Text` será processada para remover URLs, menções a usuários, hashtags, emojis, caracteres especiais e stopwords. Também será feita a conversão de todo o texto para letras minúsculas, garantindo que os dados estejam prontos para a análise de sentimentos.\n",
    "- **Remoção de Duplicatas**: Linhas duplicadas serão removidas para garantir que não haja distorções na análise de sentimentos.\n",
    "\n",
    "#### 3. Análise de Sentimentos com VADER:\n",
    "\n",
    "- A biblioteca VADER será utilizada para calcular a polaridade de cada tweet e classificá-lo como positivo, negativo ou neutro, de acordo com a pontuação de sentimento (compound score). Uma nova coluna será adicionada ao DataFrame para armazenar essa classificação.\n",
    "\n",
    "#### 4. Visualização e Interpretação:\n",
    "\n",
    "- A distribuição dos sentimentos será visualizada através de um gráfico de barras, que mostrará a quantidade de tweets classificados em cada uma das três categorias (positivo, negativo ou neutro). A quantidade de tweets será exibida ao lado de cada barra para uma melhor interpretação visual.\n",
    "\n",
    "#### 5. Conclusão:\n",
    "\n",
    "- Após a análise dos dados, será feita uma comparação entre as quantidades de tweets classificados como **positivos**, **negativos** e **neutros**, para determinar o sentimento predominante sobre o ChatGPT. Além disso, será calculada a porcentagem de tweets para cada tipo de sentimento, fornecendo uma visão clara sobre a percepção pública do ChatGPT no Twitter.\n",
    "\n",
    "- Resultado esperado: Identificar se o sentimento predominante sobre o ChatGPT é positivo, negativo ou neutro, e visualizar as porcentagens de cada categoria de sentimento.\n",
    "\n",
    "#### 6. Salvando no Pc\n",
    "\n",
    "- O dataset rotulado com os sentimentos é salvo em um arquivo CSV no computador para ser usado na segunda parte do projeto (Machine Learning).\n",
    "\n",
    "<br><br>\n",
    "\n",
    "## Parte 2: Construção do Modelo de Machine Learning\n",
    "\n",
    "#### 1. Carregamento do Dataset Rotulado:\n",
    "\n",
    "- Carregue o dataset gerado na parte 1, que contém os tweets e seus rótulos de sentimento (positivo, negativo ou neutro).\n",
    "\n",
    "#### 2. Pré-processamento de Dados para Aplicação de Machine Learning:\n",
    "\n",
    "- **Crie um pipeline** que inclua todas as transformações necessárias para preparar os tweets para o processo de Machine Learning.\n",
    "- Esse pipeline deve incluir etapas como tokenização do texto, remoção de stop words, vetorização (por exemplo, `TF-IDF`), e padronização, conforme necessário.\n",
    "- Certifique-se de que o pipeline pode ser reutilizado em datasets futuros, aplicando as mesmas transformações automaticamente aos novos dados.\n",
    "\n",
    "#### 3. Criação de um DataFrame para as Métricas:\n",
    "\n",
    "- Crie um DataFrame que armazenará as métricas de avaliação dos modelos de Machine Learning.\n",
    "- Este DataFrame deve incluir colunas como o nome do modelo, acurácia, precisão, recall, F1-score, entre outros que forem relevantes.\n",
    "\n",
    "#### 4. Construção e Avaliação do(s) Modelo(s):\n",
    "\n",
    "- Crie diferentes modelos de Machine Learning, como regressão logística, árvore de decisão, ou outro que julgar relevante para a tarefa.\n",
    "- Avalie a performance de cada modelo utilizando métricas adequadas (como acurácia, F1-score, etc.) e registre essas métricas no DataFrame criado anteriormente.\n",
    "\n",
    "- Após avaliar os modelos, salve o DataFrame com as métricas de avaliação no computador para referência futura.\n",
    "\n",
    "#### 5. Salvar o Modelo:\n",
    "\n",
    "- Salve o melhor modelo (ou todos, se for o caso) em disco para reutilização posterior. Isso permitirá que você carregue e aplique o modelo sem precisar treiná-lo novamente a partir do zero.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "## Parte 3: Testando o Modelo com Novos Dados com o Pipeline\n",
    "\n",
    "#### 1. Carregar ou Criar um Novo Dataset com Novos Dados:\n",
    "\n",
    "- Um novo conjunto de tweets será carregado ou criado. **Este dataset deve ter a mesma estrutura que o dataset original da Parte 1**, contendo uma coluna de texto (`Text`) que será usada para a transformação e predição.\n",
    "\n",
    "#### 2. Aplicar o Pipelines de Transformações criados na `Parte 2`:\n",
    "\n",
    "- Os pipelines criados e salvo na Parte 2 será carregado e aplicado ao novo dataset. Isso garantirá que as mesmas transformações (tokenização, remoção de stop words, vetorização) sejam aplicadas aos novos tweets.\n",
    "\n",
    "#### 3. Carregar o Modelo Salvo:\n",
    "\n",
    "- O modelo de Machine Learning que foi salvo na Parte 2 será carregado. Esse modelo já foi treinado com os dados rotulados e está pronto para ser aplicado aos novos dados.\n",
    "\n",
    "#### 4. Aplicar o Modelo aos Novos Dados:\n",
    "\n",
    "- Após as transformações aplicadas, o modelo será usado para prever os sentimentos (positivo, negativo ou neutro) dos novos tweets.\n",
    "- As previsões serão exibidas e podem ser salvas em um arquivo CSV para análise posterior.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "### Resumo\n",
    "\n",
    "Este projeto tem como objetivo analisar os sentimentos dos usuários no Twitter em relação ao ChatGPT utilizando duas abordagens distintas: **VADER** e **Machine Learning**. A análise de sentimentos é crucial para entender a percepção pública sobre essa tecnologia emergente, especialmente devido ao seu impacto social e potencial disruptivo.\n",
    "\n",
    "Na **primeira abordagem**, a análise será realizada com a biblioteca **VADER**, que utiliza regras baseadas em dicionários para classificar os tweets como positivos, negativos ou neutros. Este método é conhecido por sua simplicidade e eficácia em textos curtos, como tweets. A partir dessa abordagem, o sentimento predominante sobre o ChatGPT será identificado e visualizado com base em um conjunto de dados estáticos de 50.001 tweets.\n",
    "\n",
    "Na **segunda abordagem**, será construída uma pipeline de **Machine Learning** para analisar os sentimentos com base em modelos treinados. Esse processo incluirá a tokenização e vetorização do texto (usando métodos como TF-IDF) e a aplicação de diferentes algoritmos de Machine Learning, como regressão logística e árvore de decisão. O modelo de melhor performance será selecionado e salvo para posterior aplicação em novos dados.\n",
    "\n",
    "A **terceira parte** do projeto aplicará o pipeline salvo em um novo conjunto de dados, onde as mesmas transformações serão realizadas, e o modelo treinado será utilizado para prever os sentimentos dos novos tweets. Isso garantirá a reprodutibilidade do processo para futuras análises com novos dados.\n",
    "\n",
    "Por fim, os resultados das duas abordagens serão comparados para determinar qual método apresentou melhor desempenho na classificação dos sentimentos e qual foi o sentimento predominante sobre o ChatGPT no Twitter. Os pontos fortes e fracos de cada abordagem serão discutidos, permitindo uma análise crítica da aplicação de cada técnica em diferentes cenários de análise de sentimentos.\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "# Importando Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b97721d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module was compiled against NumPy C-API version 0x10 (NumPy 1.23) but the running NumPy has C-API version 0xf. Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module was compiled against NumPy C-API version 0x10 (NumPy 1.23) but the running NumPy has C-API version 0xf. Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/eduardo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manipulação de Dados\n",
    "import pandas as pd                                                  # Manipulação e análise de dados\n",
    "import numpy as np                                                   # Operações matemáticas e manipulação de arrays\n",
    "import re                                                            # Expressões regulares\n",
    "from nltk.corpus import stopwords                                    # Função para normalização do texto\n",
    "\n",
    "# Processamento de Grandes Volumes de Dados\n",
    "import pyspark                                                       # Processamento de grandes volumes de dados\n",
    "from pyspark.sql import SparkSession                                 # Criação de sessões do Spark\n",
    "from pyspark import SparkContext, SparkConf                          # Conecta e configura o cluster do Spark\n",
    "from pyspark.sql.functions import col                                # Manipulação de colunas no PySpark\n",
    "from pyspark.sql.types import StringType                             # Definição de tipos de dados no PySpark\n",
    "from pyspark.sql.functions import isnan, when, count                 # Funções para verificar e contar valores nulos\n",
    "from pyspark.sql import functions as F                               # Funções SQL do PySpark\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF  # Tokenização e vetorização de texto\n",
    "from pyspark.ml import Pipeline                                      # Criação de pipelines no PySpark\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml import Pipeline, PipelineModel, Transformer\n",
    "from pyspark.ml.feature import StringIndexer, StandardScaler, SQLTransformer\n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable\n",
    "\n",
    "\n",
    "# Análise de Sentimentos\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer # Análise de sentimentos baseada em regras\n",
    "\n",
    "# Machine Learning\n",
    "from pyspark.ml.classification import LogisticRegression             # Regressão Logística\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator  # Avaliação de classificação para ML\n",
    "from pyspark.ml.classification import RandomForestClassifier         # Algoritmo de Random Forest\n",
    "from pyspark.ml.classification import DecisionTreeClassifier         # Algoritmo de Árvore de Decisão\n",
    "from pyspark.ml.classification import NaiveBayes                     # Algoritmo Naive Bayes\n",
    "\n",
    "# Visualização de Dados\n",
    "import matplotlib.pyplot as plt                                      # Criação de gráficos\n",
    "import seaborn as sns                                                # Visualização de dados\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords') # Baixar as stopwords para processamento de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97b9fb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa o findspark e inicializa\n",
    "import findspark\n",
    "findspark.init()  # Configura automaticamente as variáveis de ambiente para PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915833ba",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "# <span style=\"color: green; font-size: 38px; font-weight: bold;\">Preparando o Ambiente Spark</span>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5cc7980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/16 15:42:06 WARN Utils: Your hostname, eduardo-Inspiron-15-3520 resolves to a loopback address: 127.0.1.1; using 192.168.0.13 instead (on interface wlp0s20f3)\n",
      "24/09/16 15:42:06 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/16 15:42:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.13:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Proj2</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f99fc835a00>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definindo semente aleatória (seed) para reprodutibilidade do notebook\n",
    "rnd_seed = 23\n",
    "np.random.seed = rnd_seed\n",
    "np.random.set_state = rnd_seed\n",
    "\n",
    "# Se houver uma sessão Spark ativa, encerre-a\n",
    "if 'sc' in globals():\n",
    "    sc.stop()\n",
    "\n",
    "if 'spark' in globals():\n",
    "    spark.stop()\n",
    "\n",
    "\n",
    "# Criando o Spark Context\n",
    "conf = SparkConf().setAppName(\"Proj2\") \\\n",
    "                  .set(\"spark.ui.showConsoleProgress\", \"false\") \\\n",
    "                  .set(\"spark.executor.heartbeatInterval\", \"20s\") \\\n",
    "                  .set(\"spark.eventLog.enabled\", \"false\") \\\n",
    "                  .set(\"spark.sql.shuffle.partitions\", \"2\") \\\n",
    "                  .set(\"spark.sql.debug.maxToStringFields\", \"100\") \\\n",
    "                  .set(\"spark.executor.memory\", \"4g\") \\\n",
    "                  .set(\"spark.driver.memory\", \"4g\") \\\n",
    "                  .set(\"spark.driver.maxResultSize\", \"2g\")  # Configuração adicional para limitar o tamanho do resultado\n",
    "\n",
    "# Criar o Spark Context e a Spark Session\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "# Ajustar o nível de log para ERROR\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "# Configurar log4j para suprimir avisos (deixar como comentário e volta ao normal)\n",
    "log4j_logger = sc._jvm.org.apache.log4j\n",
    "log4j_logger.LogManager.getLogger(\"org\").setLevel(log4j_logger.Level.ERROR)\n",
    "log4j_logger.LogManager.getLogger(\"akka\").setLevel(log4j_logger.Level.ERROR)\n",
    "\n",
    "# Visualizar o objeto spark_session\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb531be",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>\n",
    "\n",
    "# <span style=\"color: blue; font-size: 42px; font-weight: bold;\">Parte 1 - Análise de Sentimento com VADER</span>\n",
    "\n",
    "- Para esta abordagem focaremos na limpeza e manipulação de dados das colunas `Text` e `Language`, garantindo que os tweets estejam no idioma correto **(inglês)** e que o texto seja processado para remover caracteres especiais, stop words, URLs e outros elementos que não contribuam para a análise de sentimentos.\n",
    "\n",
    "<br><br><br><br><br>\n",
    "\n",
    "# <span style=\"color: green; font-size: 34px; font-weight: bold;\">1 Carregando os Dados</span>\n",
    "\n",
    "- Os dados serão carregados a partir de um arquivo CSV e gerados como um DataFrame no Apache Spark. O DataFrame é uma estrutura de dados distribuída que permite o processamento paralelo em um cluster, otimizando a performance e facilitando operações avançadas como consultas SQL e manipulações de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1719eb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " <class 'pyspark.sql.dataframe.DataFrame'> \n",
      "\n",
      "Número de Registros:  82129 \n",
      "\n",
      "+------------------------------------+-------------------+---------------------------+--------+---------+----+--------+----------+----------+------------+---------+----------+--------------+--------+------+-----+-----------+--------------+-------+-------------+\n",
      "|                            Datetime|           Tweet Id|                       Text|Username|Permalink|User|Outlinks|CountLinks|ReplyCount|RetweetCount|LikeCount|QuoteCount|ConversationId|Language|Source|Media|QuotedTweet|MentionedUsers|hashtag|hastag_counts|\n",
      "+------------------------------------+-------------------+---------------------------+--------+---------+----+--------+----------+----------+------------+---------+----------+--------------+--------+------+-----+-----------+--------------+-------+-------------+\n",
      "|                2023-01-22 13:44:...|1617156270871699456|ChatGPTで遊ぶの忘れてた！！|    NULL|     NULL|NULL|    NULL|      NULL|      NULL|        NULL|     NULL|      NULL|          NULL|    NULL|  NULL| NULL|       NULL|          NULL|   NULL|         NULL|\n",
      "|書類作るコード書いてみてほしいのと、|               NULL|                       NULL|    NULL|     NULL|NULL|    NULL|      NULL|      NULL|        NULL|     NULL|      NULL|          NULL|    NULL|  NULL| NULL|       NULL|          NULL|   NULL|         NULL|\n",
      "+------------------------------------+-------------------+---------------------------+--------+---------+----+--------+----------+----------+------------+---------+----------+--------------+--------+------+-----+-----------+--------------+-------+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Carrega os dados\n",
    "dados = spark.read.csv('dados/chatgpt1.csv', inferSchema = True, header = True)\n",
    "\n",
    "print('\\n', type(dados), '\\n')\n",
    "\n",
    "# Número de registros\n",
    "print('Número de Registros: ', dados.count(), '\\n')\n",
    "\n",
    "# Visualiza os dados no padrão do Spark DataFrame\n",
    "dados.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd30ee39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Datetime: string (nullable = true)\n",
      " |-- Tweet Id: string (nullable = true)\n",
      " |-- Text: string (nullable = true)\n",
      " |-- Username: string (nullable = true)\n",
      " |-- Permalink: string (nullable = true)\n",
      " |-- User: string (nullable = true)\n",
      " |-- Outlinks: string (nullable = true)\n",
      " |-- CountLinks: string (nullable = true)\n",
      " |-- ReplyCount: string (nullable = true)\n",
      " |-- RetweetCount: string (nullable = true)\n",
      " |-- LikeCount: string (nullable = true)\n",
      " |-- QuoteCount: string (nullable = true)\n",
      " |-- ConversationId: string (nullable = true)\n",
      " |-- Language: string (nullable = true)\n",
      " |-- Source: string (nullable = true)\n",
      " |-- Media: string (nullable = true)\n",
      " |-- QuotedTweet: string (nullable = true)\n",
      " |-- MentionedUsers: string (nullable = true)\n",
      " |-- hashtag: string (nullable = true)\n",
      " |-- hastag_counts: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Schema\n",
    "dados.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63467564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>Permalink</th>\n",
       "      <th>User</th>\n",
       "      <th>Outlinks</th>\n",
       "      <th>CountLinks</th>\n",
       "      <th>ReplyCount</th>\n",
       "      <th>RetweetCount</th>\n",
       "      <th>LikeCount</th>\n",
       "      <th>QuoteCount</th>\n",
       "      <th>ConversationId</th>\n",
       "      <th>Language</th>\n",
       "      <th>Source</th>\n",
       "      <th>Media</th>\n",
       "      <th>QuotedTweet</th>\n",
       "      <th>MentionedUsers</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>hastag_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morgen startet @reg_schulz - und am Di um 12 b...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#ChatGPT #visionary #ArtificialIntelligence #f...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Datetime Tweet Id  Text Username  \\\n",
       "0  Morgen startet @reg_schulz - und am Di um 12 b...     None  None     None   \n",
       "1  #ChatGPT #visionary #ArtificialIntelligence #f...     None  None     None   \n",
       "\n",
       "  Permalink  User Outlinks CountLinks ReplyCount RetweetCount LikeCount  \\\n",
       "0      None  None     None       None       None         None      None   \n",
       "1      None  None     None       None       None         None      None   \n",
       "\n",
       "  QuoteCount ConversationId Language Source Media QuotedTweet MentionedUsers  \\\n",
       "0       None           None     None   None  None        None           None   \n",
       "1       None           None     None   None  None        None           None   \n",
       "\n",
       "  hashtag hastag_counts  \n",
       "0    None          None  \n",
       "1    None          None  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza duas linhas aleatórias no formato dataframe do pandas (apenas para visualização)\n",
    "dados.sample(False, 0.10).limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef4c216",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "# <span style=\"color: green; font-size: 34px; font-weight: bold;\">Análise Exploratória Inicial dos Dados </span>\n",
    "\n",
    "<br>\n",
    "\n",
    "### Criação de Função Para Análise Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e33aad02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A função foi criada com sucesso.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def funcao_analise_inicial(df):\n",
    "    # Exibir o esquema do DataFrame\n",
    "    print(\"\\n\\n INFO \\n\\n\")\n",
    "    df.printSchema()\n",
    "\n",
    "    # Número total de registros\n",
    "    print(f\"\\nNúmero total de registros: {df.count()}\")\n",
    "    \n",
    "    # Verificar valores ausentes\n",
    "    print(\"\\n\\nVerificando valores ausentes:\\n\")\n",
    "    df_ausentes = df.select([count(when(col(c).isNull() | isnan(c), c)).alias(c) for c in df.columns])\n",
    "    df_ausentes.show()\n",
    "\n",
    "    # Verificar valores duplicados\n",
    "    num_linhas_duplicadas = df.count() - df.dropDuplicates().count()\n",
    "    porcentagem_linhas_duplicadas = (num_linhas_duplicadas / df.count()) * 100\n",
    "    print(f\"\\n\\nExistem valores duplicados: {num_linhas_duplicadas > 0}\")\n",
    "    if num_linhas_duplicadas > 0:\n",
    "        print(f\"Número de Linhas Duplicadas: {num_linhas_duplicadas}\")\n",
    "        print(f\"Porcentagem de Linhas Duplicadas: {porcentagem_linhas_duplicadas:.2f}%\")\n",
    "    else:\n",
    "        print(\"Nenhuma variável possui valores duplicados.\")\n",
    "\n",
    "    # Verificação de caracteres especiais\n",
    "    caracteres_especiais = re.compile('[@_!#$%^&*<>()?/\\\\|}{~:]')\n",
    "    colunas_com_caracteres_especiais = {}\n",
    "\n",
    "    # Iterar sobre colunas do tipo string\n",
    "    for coluna in df.columns:\n",
    "        if dict(df.dtypes)[coluna] == 'string':\n",
    "            contem_caracteres_especiais = df.filter(df[coluna].rlike('[@_!#$%^&*<>()?/\\\\|}{~:]')).count() > 0\n",
    "            if contem_caracteres_especiais:\n",
    "                indices_com_caracteres_especiais = df.filter(df[coluna].rlike('[@_!#$%^&*<>()?/\\\\|}{~:]')).select(coluna).rdd.map(lambda row: row[coluna]).collect()\n",
    "                colunas_com_caracteres_especiais[coluna] = indices_com_caracteres_especiais\n",
    "\n",
    "    # Exibe o resultado sobre caracteres especiais\n",
    "    print(\"\\n\\nExistem caracteres especiais nas colunas:\", bool(colunas_com_caracteres_especiais))\n",
    "    if colunas_com_caracteres_especiais:\n",
    "        print(\"\\nColunas com caracteres especiais e exemplos de valores:\")\n",
    "        for coluna, indices in colunas_com_caracteres_especiais.items():\n",
    "            print(f\"\\n Coluna [ {coluna} ]\")\n",
    "            # print(f\"\\n Coluna [ {coluna} ]: Exemplo de valores com caracteres especiais: {indices[:5]}\")\n",
    "    else:\n",
    "        print(\"\\nNenhuma coluna possui caracteres especiais.\")\n",
    "\n",
    "print('A função foi criada com sucesso.\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0d91892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " INFO \n",
      "\n",
      "\n",
      "root\n",
      " |-- Datetime: string (nullable = true)\n",
      " |-- Tweet Id: string (nullable = true)\n",
      " |-- Text: string (nullable = true)\n",
      " |-- Username: string (nullable = true)\n",
      " |-- Permalink: string (nullable = true)\n",
      " |-- User: string (nullable = true)\n",
      " |-- Outlinks: string (nullable = true)\n",
      " |-- CountLinks: string (nullable = true)\n",
      " |-- ReplyCount: string (nullable = true)\n",
      " |-- RetweetCount: string (nullable = true)\n",
      " |-- LikeCount: string (nullable = true)\n",
      " |-- QuoteCount: string (nullable = true)\n",
      " |-- ConversationId: string (nullable = true)\n",
      " |-- Language: string (nullable = true)\n",
      " |-- Source: string (nullable = true)\n",
      " |-- Media: string (nullable = true)\n",
      " |-- QuotedTweet: string (nullable = true)\n",
      " |-- MentionedUsers: string (nullable = true)\n",
      " |-- hashtag: string (nullable = true)\n",
      " |-- hastag_counts: string (nullable = true)\n",
      "\n",
      "\n",
      "Número total de registros: 82129\n",
      "\n",
      "\n",
      "Verificando valores ausentes:\n",
      "\n",
      "+--------+--------+-----+--------+---------+-----+--------+----------+----------+------------+---------+----------+--------------+--------+------+-----+-----------+--------------+-------+-------------+\n",
      "|Datetime|Tweet Id| Text|Username|Permalink| User|Outlinks|CountLinks|ReplyCount|RetweetCount|LikeCount|QuoteCount|ConversationId|Language|Source|Media|QuotedTweet|MentionedUsers|hashtag|hastag_counts|\n",
      "+--------+--------+-----+--------+---------+-----+--------+----------+----------+------------+---------+----------+--------------+--------+------+-----+-----------+--------------+-------+-------------+\n",
      "|       0|   13600|14970|   31749|    38840|39949|   54723|     54087|     32651|       32334|    32203|     32164|         32157|   42913| 46679|72204|      64378|         53380|  47139|        48168|\n",
      "+--------+--------+-----+--------+---------+-----+--------+----------+----------+------------+---------+----------+--------------+--------+------+-----+-----------+--------------+-------+-------------+\n",
      "\n",
      "\n",
      "\n",
      "Existem valores duplicados: True\n",
      "Número de Linhas Duplicadas: 1946\n",
      "Porcentagem de Linhas Duplicadas: 2.37%\n",
      "\n",
      "\n",
      "Existem caracteres especiais nas colunas: True\n",
      "\n",
      "Colunas com caracteres especiais e exemplos de valores:\n",
      "\n",
      " Coluna [ Datetime ]\n",
      "\n",
      " Coluna [ Tweet Id ]\n",
      "\n",
      " Coluna [ Text ]\n",
      "\n",
      " Coluna [ Username ]\n",
      "\n",
      " Coluna [ Permalink ]\n",
      "\n",
      " Coluna [ User ]\n",
      "\n",
      " Coluna [ Outlinks ]\n",
      "\n",
      " Coluna [ CountLinks ]\n",
      "\n",
      " Coluna [ ReplyCount ]\n",
      "\n",
      " Coluna [ RetweetCount ]\n",
      "\n",
      " Coluna [ LikeCount ]\n",
      "\n",
      " Coluna [ QuoteCount ]\n",
      "\n",
      " Coluna [ ConversationId ]\n",
      "\n",
      " Coluna [ Language ]\n",
      "\n",
      " Coluna [ Source ]\n",
      "\n",
      " Coluna [ Media ]\n",
      "\n",
      " Coluna [ QuotedTweet ]\n",
      "\n",
      " Coluna [ MentionedUsers ]\n",
      "\n",
      " Coluna [ hashtag ]\n",
      "\n",
      " Coluna [ hastag_counts ]\n"
     ]
    }
   ],
   "source": [
    "# Chama a Função Analise inicial\n",
    "funcao_analise_inicial(dados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73754333",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Analisando Coluna `Language`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab80b117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qtd Idiomas:  4353 \n",
      "\n",
      "\n",
      "\n",
      "Tabela com Tipos de Idiomas mais frequentes:\n",
      "\n",
      "+--------------------+-----+\n",
      "|            Language|count|\n",
      "+--------------------+-----+\n",
      "|                NULL|42913|\n",
      "|                  en|21677|\n",
      "|                  ja| 2741|\n",
      "|                  es| 2354|\n",
      "|                  fr| 1673|\n",
      "|                  pt|  888|\n",
      "|                  de|  808|\n",
      "|\"<a href=\"\"https:...|  612|\n",
      "|                 und|  344|\n",
      "|                  tr|  302|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificar quantos idiomas únicos existem na coluna 'Language'\n",
    "qtd_idiomas = dados.select(\"Language\").distinct().count()\n",
    "print('Qtd Idiomas: ', qtd_idiomas, '\\n\\n')\n",
    "\n",
    "# Verificar os 10 idiomas mais frequentes na coluna 'Language'\n",
    "print('\\nTabela com Tipos de Idiomas mais frequentes:\\n')\n",
    "idiomas_frequentes = dados.groupBy(\"Language\").count().orderBy(F.desc(\"count\")).limit(10)\n",
    "idiomas_frequentes.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717236c0",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "# <span style=\"color: green; font-size: 34px; font-weight: bold;\">2. Limpeza e Manipulação dos Dados</span>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "### Filtrando os Dados Apenas do Idioma Inglês e Selecionando Coluna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19f68fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+------------+---------+\n",
      "|                Text|Language|RetweetCount|LikeCount|\n",
      "+--------------------+--------+------------+---------+\n",
      "|@AlexandrovnaIng ...|      en|           0|        5|\n",
      "|Bow down to chatG...|      en|           0|        2|\n",
      "+--------------------+--------+------------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtrar o DataFrame para manter apenas as linhas com o idioma 'en'\n",
    "df_english = dados.filter(dados['Language'] == 'en')\n",
    "\n",
    "# Selecionar apenas as colunas desejadas\n",
    "df_english = df_english.select('Text', 'Language', 'RetweetCount', 'LikeCount')\n",
    "\n",
    "# Verificar as primeiras linhas do DataFrame filtrado\n",
    "df_english.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a674ac28",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Tratando Coluna `Text`\n",
    "\n",
    "#### Criando Funções Para Limpar e Normalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cffdce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funcões criadas com sucesso.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Função para limpar o texto\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Limpa o texto removendo URLs, menções, hashtags, emojis, pontuações,\n",
    "    caracteres especiais (incluindo underline) e converte para minúsculas.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text)  # Remove menções (@usuário)\n",
    "    text = re.sub(r'#\\w+', '', text)  # Remove hashtags (#)\n",
    "    text = re.sub(r'[^\\w\\s\\']', '', text)  # Remove emojis e pontuações, exceto apóstrofos\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove múltiplos espaços\n",
    "    text = text.replace('_', '')  # Remove underlines manualmente\n",
    "    text = text.lower().strip()  # Converte para minúsculas e remove espaços extras\n",
    "    return text\n",
    "\n",
    "# Função para remover stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"\n",
    "    Remove stopwords (palavras comuns) do texto para focar nas palavras mais relevantes.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    filtered_text = ' '.join([word for word in words if word not in stop_words])\n",
    "    return filtered_text\n",
    "\n",
    "# Converter as funções para UDFs (User Defined Functions) no PySpark\n",
    "clean_text_udf = udf(lambda text: clean_text(text), StringType())\n",
    "remove_stopwords_udf = udf(lambda text: remove_stopwords(text), StringType())\n",
    "\n",
    "print('Funcões criadas com sucesso.\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16aecbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------+--------+------------+---------+\n",
      "|Text                                                 |Language|RetweetCount|LikeCount|\n",
      "+-----------------------------------------------------+--------+------------+---------+\n",
      "|prohibition chatgpt added honor code daughters school|en      |0           |5        |\n",
      "|bow chatgpt                                          |en      |0           |2        |\n",
      "+-----------------------------------------------------+--------+------------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicar as funções de limpeza e normalização de texto ao DataFrame\n",
    "df_english = df_english.withColumn('Text', clean_text_udf(col('Text')))\n",
    "df_english = df_english.withColumn('Text', remove_stopwords_udf(col('Text')))\n",
    "\n",
    "# Exibir as primeiras linhas após a aplicação das funções\n",
    "df_english.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bc6bb7",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Removendo Linhas Duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2331a39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de linhas duplicadas antes de remover: 2489\n",
      "Quantidade de linhas duplicadas após remover: 0\n"
     ]
    }
   ],
   "source": [
    "# Verificar a quantidade de linhas duplicadas antes de remover\n",
    "qtd_duplicadas_antes = df_english.count() - df_english.dropDuplicates().count()\n",
    "print(f\"Quantidade de linhas duplicadas antes de remover: {qtd_duplicadas_antes}\")\n",
    "\n",
    "# Remover as linhas duplicadas\n",
    "df_english = df_english.dropDuplicates()\n",
    "\n",
    "# Verificar a quantidade de linhas duplicadas novamente\n",
    "qtd_duplicadas_depois = df_english.count() - df_english.dropDuplicates().count()\n",
    "print(f\"Quantidade de linhas duplicadas após remover: {qtd_duplicadas_depois}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c134fd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " INFO \n",
      "\n",
      "\n",
      "root\n",
      " |-- Text: string (nullable = true)\n",
      " |-- Language: string (nullable = true)\n",
      " |-- RetweetCount: string (nullable = true)\n",
      " |-- LikeCount: string (nullable = true)\n",
      "\n",
      "\n",
      "Número total de registros: 19188\n",
      "\n",
      "\n",
      "Verificando valores ausentes:\n",
      "\n",
      "+----+--------+------------+---------+\n",
      "|Text|Language|RetweetCount|LikeCount|\n",
      "+----+--------+------------+---------+\n",
      "|   0|       0|           0|        0|\n",
      "+----+--------+------------+---------+\n",
      "\n",
      "\n",
      "\n",
      "Existem valores duplicados: False\n",
      "Nenhuma variável possui valores duplicados.\n",
      "\n",
      "\n",
      "Existem caracteres especiais nas colunas: False\n",
      "\n",
      "Nenhuma coluna possui caracteres especiais.\n"
     ]
    }
   ],
   "source": [
    "# Chama a Função Analise inicial\n",
    "funcao_analise_inicial(df_english)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fa3001",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "# <span style=\"color: green; font-size: 34px; font-weight: bold;\">3. Aplicar Análise de Sentimentos com VADER</span>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "#### Criando e Aplicando Função Para Aplicar a Análise de Sentimentos em Cada Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17231012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+------------+---------+----------+\n",
      "|                Text|Language|RetweetCount|LikeCount|Sentimento|\n",
      "+--------------------+--------+------------+---------+----------+\n",
      "|         bow chatgpt|      en|           0|        2|    neutro|\n",
      "|chatgpt runs 10k ...|      en|           0|        0|    neutro|\n",
      "|aint got time age...|      en|           0|        2|    neutro|\n",
      "|leverage chatgpty...|      en|           0|        5|  positivo|\n",
      "|google freaking c...|      en|           0|        0|  negativo|\n",
      "+--------------------+--------+------------+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inicializar o analisador de sentimentos VADER\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Função para aplicar a análise de sentimentos em cada tweet\n",
    "def apply_vader(text):\n",
    "    \"\"\"\n",
    "    Recebe o texto de um tweet, calcula a pontuação de sentimento usando VADER\n",
    "    e retorna a classificação (positivo, neutro ou negativo).\n",
    "    \"\"\"\n",
    "    scores = analyzer.polarity_scores(text)  # Obter as pontuações de sentimento\n",
    "    compound = scores['compound']            # O \"compound\" é a pontuação geral de sentimento\n",
    "    \n",
    "    if compound >= 0.05:\n",
    "        return 'positivo'\n",
    "    elif compound <= -0.05:\n",
    "        return 'negativo'\n",
    "    else:\n",
    "        return 'neutro'\n",
    "\n",
    "# Criar uma UDF (User Defined Function) para aplicar o VADER ao PySpark\n",
    "vader_udf = udf(apply_vader, StringType())\n",
    "\n",
    "# Aplicar a função de análise de sentimentos ao DataFrame Spark\n",
    "df_english = df_english.withColumn(\"Sentimento\", vader_udf(df_english[\"Text\"]))\n",
    "\n",
    "# Verificar as primeiras linhas para confirmar a nova coluna\n",
    "df_english.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45bd497",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "# <span style=\"color: green; font-size: 34px; font-weight: bold;\">4. Visualização dos Resultados</span>\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Visualizando por Gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a965672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Contar a quantidade de tweets por tipo de sentimento\n",
    "sentiment_counts = df_english.groupBy(\"Sentimento\").count().orderBy(\"count\", ascending=False)\n",
    "\n",
    "# Coletar os resultados para visualização em gráfico\n",
    "sentiment_counts_pandas = sentiment_counts.toPandas()\n",
    "\n",
    "# Plotar um gráfico de barras para visualizar a distribuição dos sentimentos\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(x=sentiment_counts_pandas['Sentimento'], y=sentiment_counts_pandas['count'], palette='viridis')\n",
    "\n",
    "# Adicionar os valores ao lado direito de cada barra\n",
    "for index, value in enumerate(sentiment_counts_pandas['count']):\n",
    "    plt.text(index, value, f'{value}', ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "# Configurar o gráfico\n",
    "plt.title('Distribuição de Sentimentos sobre o ChatGPT no Twitter')\n",
    "plt.xlabel('Tipo de Sentimento')\n",
    "plt.ylabel('Quantidade de Tweets')\n",
    "\n",
    "# Mostrar o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacdb261",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "# <span style=\"color: green; font-size: 34px; font-weight: bold;\">5. Conclusão</span>\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Exibindo os Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6117c78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contagem dos Sentimentos:\n",
      "+----------+-----+\n",
      "|Sentimento|count|\n",
      "+----------+-----+\n",
      "|  positivo| 8808|\n",
      "|    neutro| 7095|\n",
      "|  negativo| 3285|\n",
      "+----------+-----+\n",
      "\n",
      "\n",
      "O sentimento predominante sobre o ChatGPT é: Positivo\n",
      "\n",
      "\n",
      "Porcentagem de cada sentimento:\n",
      "+----------+-----+------------------+\n",
      "|Sentimento|count|        percentage|\n",
      "+----------+-----+------------------+\n",
      "|  positivo| 8808| 45.90368980612883|\n",
      "|    neutro| 7095| 36.97623514696685|\n",
      "|  negativo| 3285|17.120075046904315|\n",
      "+----------+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exibir a contagem dos tipos de sentimentos\n",
    "print(\"\\nContagem dos Sentimentos:\")\n",
    "sentiment_counts.show()\n",
    "\n",
    "# Conclusão sobre o sentimento predominante\n",
    "sentimento_predominante = sentiment_counts.orderBy(\"count\", ascending=False).first()[\"Sentimento\"]\n",
    "print(f\"\\nO sentimento predominante sobre o ChatGPT é: {sentimento_predominante.capitalize()}\")\n",
    "\n",
    "# Calcular a porcentagem de tweets para cada sentimento\n",
    "total_tweets = df_english.count()\n",
    "sentiment_percentage = sentiment_counts.withColumn(\"percentage\", (sentiment_counts[\"count\"] / total_tweets) * 100)\n",
    "\n",
    "# Exibir a porcentagem de cada sentimento\n",
    "print(\"\\n\\nPorcentagem de cada sentimento:\")\n",
    "sentiment_percentage.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05084897",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "# <span style=\"color: green; font-size: 34px; font-weight: bold;\">6. Salvando os Resultados</span>\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Salvando no PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efee7e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos os arquivos foram salvos com sucesso.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Converter os DataFrames PySpark para Pandas\n",
    "df_english_pandas = df_english.toPandas()\n",
    "sentiment_counts_pandas = sentiment_counts.toPandas()\n",
    "\n",
    "# Defina o caminho da pasta onde deseja salvar os arquivos\n",
    "output_folder = \"resultados/\"\n",
    "\n",
    "# Salvar o DataFrame df_english como CSV\n",
    "df_english_pandas.to_csv(f\"{output_folder}/tweets_sentiment_analysis.csv\", index=False)\n",
    "\n",
    "# Salvar o DataFrame sentiment_counts como CSV\n",
    "sentiment_counts_pandas.to_csv(f\"{output_folder}/sentiment_counts.csv\", index=False)\n",
    "\n",
    "# Salvar o DataFrame sentiment_percentage como CSV\n",
    "sentiment_percentage_pandas = sentiment_percentage.toPandas()\n",
    "sentiment_percentage_pandas.to_csv(f\"{output_folder}/sentiment_percentage.csv\", index=False)\n",
    "\n",
    "print('Todos os arquivos foram salvos com sucesso.\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4639e297",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>\n",
    "\n",
    "# <span style=\"color: blue; font-size: 44px; font-weight: bold;\">Parte 2 - Construção do Modelo de Machine Learning</span>\n",
    "\n",
    "<br><br><br><br><br>\n",
    "\n",
    "# <span style=\"color: green; font-size: 34px; font-weight: bold;\">1 Carregando os Dados</span>\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Os dados carregados é o dataset gerado na parte 1 com `acréscimo de tweets negativos`**, e que contém os tweets e seus rótulos de sentimento (positivo, negativo ou neutro)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e6a8349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " <class 'pyspark.sql.dataframe.DataFrame'> \n",
      "\n",
      "Número de Registros:  23839 \n",
      "\n",
      "+--------------------+--------+------------+---------+----------+\n",
      "|                Text|Language|RetweetCount|LikeCount|Sentimento|\n",
      "+--------------------+--------+------------+---------+----------+\n",
      "|leverage chatgpty...|      en|           0|        5|  positivo|\n",
      "|google freaking c...|      en|           0|        0|  negativo|\n",
      "|learn chatgpt get...|      en|          49|      607|  negativo|\n",
      "|following creatio...|      en|           0|        0|  positivo|\n",
      "|seems like chatgp...|      en|           0|        0|  positivo|\n",
      "+--------------------+--------+------------+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Carrega os dados\n",
    "dados = spark.read.csv('resultados/tweets_sentiment_analysis2.csv', inferSchema = True, header = True)\n",
    "\n",
    "print('\\n', type(dados), '\\n')\n",
    "\n",
    "# Número de registros\n",
    "print('Número de Registros: ', dados.count(), '\\n')\n",
    "\n",
    "# Visualiza os dados no padrão do Spark DataFrame\n",
    "dados.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6634835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Text: string (nullable = true)\n",
      " |-- Language: string (nullable = true)\n",
      " |-- RetweetCount: integer (nullable = true)\n",
      " |-- LikeCount: integer (nullable = true)\n",
      " |-- Sentimento: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Schema\n",
    "dados.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfbef6e",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "# <span style=\"color: green; font-size: 34px; font-weight: bold;\">2. Pré-Processamento de Dados para Aplicação de Machine Learning</span>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "### Criando e Salvando um Pipeline com as Transformações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9ab2b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline criado, aplicado e salvo com sucesso!\n",
      "\n",
      "\n",
      "Dados de treino transformados:\n",
      "+--------------------+----------+---------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                Text|Sentimento|Sentiment_Value|               words|         rawFeatures|            features|      scaledFeatures|\n",
      "+--------------------+----------+---------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|   ' ' new disruptor|    neutro|              0|[', ', new, disru...|(10000,[585,1282,...|(10000,[585,1282,...|(10000,[585,1282,...|\n",
      "|' take 20 jobs wi...|  positivo|              1|[', take, 20, job...|(10000,[22,855,91...|(10000,[22,855,91...|(10000,[22,855,91...|\n",
      "+--------------------+----------+---------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "Dados de teste transformados:\n",
      "+--------------------+----------+---------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                Text|Sentimento|Sentiment_Value|               words|         rawFeatures|            features|      scaledFeatures|\n",
      "+--------------------+----------+---------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|' analysts eran s...|  positivo|              1|[', analysts, era...|(10000,[125,269,8...|(10000,[125,269,8...|(10000,[125,269,8...|\n",
      "|'according inform...|  positivo|              1|['according, info...|(10000,[126,594,1...|(10000,[126,594,1...|(10000,[126,594,1...|\n",
      "+--------------------+----------+---------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 1.  Seleção de Colunas para Tratamento\n",
    "\n",
    "# 1.1 Selecionar as colunas 'Text' e 'Sentimento' e remoção de valores nulos\n",
    "dados_selecionados = dados.select('Text', 'Sentimento').filter(dados[\"Text\"].isNotNull())\n",
    "\n",
    "\n",
    "## 2. Aplicando Label Encoding na Variável Alvo\n",
    "\n",
    "# 2.1 Aplicar Label Encoding na coluna 'Sentimento'\n",
    "dados_com_valor_sentimento = dados_selecionados.withColumn(\n",
    "    \"Sentiment_Value\",\n",
    "    when(dados_selecionados[\"Sentimento\"] == \"positivo\", 1)\n",
    "    .when(dados_selecionados[\"Sentimento\"] == \"neutro\", 0)\n",
    "    .when(dados_selecionados[\"Sentimento\"] == \"negativo\", 2)\n",
    ")\n",
    "\n",
    "\n",
    "## 3. Divisão dos Dados em Treino e Teste\n",
    "\n",
    "# 3.1 Dividir os dados em treino e teste (80% treino, 20% teste)\n",
    "train_data, test_data = dados_com_valor_sentimento.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "\n",
    "## 4. Vetorização da Variável 'Text' (convertendo para formato numérico)\n",
    "\n",
    "# 4.1 Tokenizar o texto (transformar o texto em palavras)\n",
    "tokenizer = Tokenizer(inputCol=\"Text\", outputCol=\"words\")\n",
    "\n",
    "# 4.2 Aplicar HashingTF (ou CountVectorizer) para criar a matriz de features\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "\n",
    "# 4.3 Aplicar TF-IDF para ajustar os pesos das palavras\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "\n",
    "\n",
    "## 5 Aplicando Padronização na Coluna 'features'\n",
    "\n",
    "# 5.1 Usar StandardScaler para padronizar a coluna 'features'\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=False)\n",
    "\n",
    "\n",
    "## 6. Criando e Aplicando o Pipeline\n",
    "\n",
    "# 6.1 Configurando os Estágios do Pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, idf, scaler])\n",
    "\n",
    "# 6.2 Ajustar o pipeline **somente nos dados de treino**\n",
    "pipeline_model = pipeline.fit(train_data)\n",
    "\n",
    "# 6.3 Aplicar o pipeline nos dados de treino e teste\n",
    "train_data = pipeline_model.transform(train_data)\n",
    "test_data = pipeline_model.transform(test_data)\n",
    "\n",
    "\n",
    "## 7. Salvando o Pipeline\n",
    "\n",
    "# 7.1 Opcional: Salvar o pipeline para uso futuro\n",
    "pipeline_model.write().overwrite().save(\"sentiment_analysis_pipeline\")\n",
    "\n",
    "print(\"Pipeline criado, aplicado e salvo com sucesso!\\n\\n\")\n",
    "\n",
    "# Exibir os dados transformados de treino e teste\n",
    "print(\"Dados de treino transformados:\")\n",
    "train_data.show(2)\n",
    "\n",
    "print(\"Dados de teste transformados:\")\n",
    "test_data.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0386ed4",
   "metadata": {},
   "source": [
    "### Etapas do Pipeline\n",
    "\n",
    "- **1. Seleção de Colunas para Tratamento**: Selecionam-se apenas as colunas Text e Sentimento do dataset original, e remove-se qualquer linha que tenha valor nulo na coluna Text.\n",
    "\n",
    "- **2. Aplicação de Label Encoding na Variável Alvo**: Transforma-se a coluna Sentimento em valores numéricos usando Label Encoding, onde:\n",
    "\n",
    "  - \"positivo\" = 1\n",
    "  - \"neutro\" = 0\n",
    "  - \"negativo\" = 2.\n",
    "  \n",
    "- **3. Divisão dos Dados em Treino e Teste**: Os dados são divididos em dois subconjuntos: 80% para treino e 20% para teste. Essa divisão garante que o modelo seja treinado e avaliado em conjuntos de dados distintos.\n",
    "  \n",
    "- **4.1 Tokenização**: O texto foi tokenizado, transformando o conteúdo em uma lista de palavras individuais, que estão na coluna words.\n",
    "\n",
    "- **4.2 Vetorização (rawFeatures)**: A vetorização do texto em uma representação numérica foi bem-sucedida. A coluna rawFeatures mostra a transformação das palavras em índices e suas respectivas contagens.\n",
    "\n",
    "- **4.3 TF-IDF (features)**: O ajuste dos pesos das palavras usando TF-IDF foi aplicado corretamente, resultando em uma coluna features que reflete a importância relativa de cada palavra no contexto dos tweets.\n",
    "\n",
    "- **5. Padronização (scaledFeatures)**: A padronização das features foi aplicada corretamente, garantindo que os dados estejam em uma escala adequada para o uso em modelos de Machine Learning.\n",
    "\n",
    "- **6. Criação e Aplicação do Pipeline**: Um pipeline é criado com as etapas de tokenização, vetorização, aplicação de TF-IDF e padronização. O pipeline é ajustado nos dados de treino e, em seguida, aplicado tanto nos dados de treino quanto nos dados de teste.\n",
    "\n",
    "- **7. Salvando o Pipeline**: O pipeline ajustado é salvo em disco para que possa ser reutilizado futuramente, sem a necessidade de refazer todo o processo de ajuste nas mesmas etapas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a792302",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "# <span style=\"color: green; font-size: 34px; font-weight: bold;\">3. Criação de um DataFrame para as Métricas:</span>\n",
    "\n",
    "<br>\n",
    "\n",
    "### Criando o Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08cc9aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe criado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Criar um dataframe para armazenar as métricas de cada modelo\n",
    "df_modelos = pd.DataFrame(columns=[\"Modelo\", \"Acurácia\", \"F1-Score\"])\n",
    "\n",
    "print('Dataframe criado com sucesso.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff796c3d",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "# <span style=\"color: green; font-size: 34px; font-weight: bold;\">4. Construção e Avaliação do(s) Modelo(s):</span>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "# 1. Regressão Logística\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f9c5ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exibindo as Previsões:\n",
      "+--------------------+---------------+----------+\n",
      "|                Text|Sentiment_Value|prediction|\n",
      "+--------------------+---------------+----------+\n",
      "|' analysts eran s...|              1|       1.0|\n",
      "|'according inform...|              1|       2.0|\n",
      "|'s chatgpt amp ai...|              1|       1.0|\n",
      "|'s first day heme...|              0|       2.0|\n",
      "+--------------------+---------------+----------+\n",
      "only showing top 4 rows\n",
      "\n",
      "\n",
      "Acurácia do modelo Regressão Logística: 0.72\n",
      "\n",
      "F1-Score do modelo Regressão Logística: 0.72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Criar o modelo de Regressão Logística\n",
    "lr = LogisticRegression(featuresCol='scaledFeatures', labelCol='Sentiment_Value')\n",
    "\n",
    "# Treinar o modelo com os dados de treino\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "# Previsões nos dados de teste\n",
    "predictions = lr_model.transform(test_data)\n",
    "\n",
    "# Mostrar as previsões\n",
    "print('\\nExibindo as Previsões:')\n",
    "predictions.select(\"Text\", \"Sentiment_Value\", \"prediction\").show(4)\n",
    "\n",
    "# Avaliador para classificação (Acurácia)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Sentiment_Value\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"\\nAcurácia do modelo Regressão Logística: {accuracy:.2f}\")\n",
    "\n",
    "# Avaliador para classificação (F1-Score)\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"Sentiment_Value\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1_score = f1_evaluator.evaluate(predictions)\n",
    "print(f\"\\nF1-Score do modelo Regressão Logística: {f1_score:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afab1bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Acurácia</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regressão Logística</td>\n",
       "      <td>0.715157</td>\n",
       "      <td>0.715118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Modelo  Acurácia  F1-Score\n",
       "0  Regressão Logística  0.715157  0.715118"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Salvar as métricas no dataframe df_modelos\n",
    "df_modelos = df_modelos.append({\n",
    "    \"Modelo\": \"Regressão Logística\",\n",
    "    \"Acurácia\": accuracy,\n",
    "    \"F1-Score\": f1_score\n",
    "}, ignore_index=True)\n",
    "\n",
    "# Exibir o dataframe com as métricas\n",
    "display(df_modelos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1db7dc",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# 1.2 Regressão Logística (com configurações de hiperparâmetros)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73303732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exibindo as Previsões (versão 1.2):\n",
      "+--------------------+---------------+----------+\n",
      "|                Text|Sentiment_Value|prediction|\n",
      "+--------------------+---------------+----------+\n",
      "|' analysts eran s...|              1|       1.0|\n",
      "|'according inform...|              1|       0.0|\n",
      "|'s chatgpt amp ai...|              1|       1.0|\n",
      "|'s first day heme...|              0|       0.0|\n",
      "+--------------------+---------------+----------+\n",
      "only showing top 4 rows\n",
      "\n",
      "\n",
      "Acurácia do modelo Regressão Logística (versão 1.2): 0.80\n",
      "\n",
      "F1-Score do modelo Regressão Logística (versão 1.2): 0.80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Criar o modelo de Regressão Logística versão 1.2 com hiperparâmetros ajustados\n",
    "# Ajustes de hiperparâmetros:\n",
    "# maxIter: número máximo de iterações\n",
    "# regParam: parâmetro de regularização\n",
    "# elasticNetParam: equilíbrio entre L1 e L2 (0.0 = L2, 1.0 = L1)\n",
    "lr_v1_2 = LogisticRegression(featuresCol='scaledFeatures', labelCol='Sentiment_Value', \n",
    "                             maxIter=100, regParam=0.01, elasticNetParam=0.8)\n",
    "\n",
    "# Treinar o modelo com os dados de treino\n",
    "lr_model_v1_2 = lr_v1_2.fit(train_data)\n",
    "\n",
    "# Previsões nos dados de teste\n",
    "predictions_v1_2 = lr_model_v1_2.transform(test_data)\n",
    "\n",
    "# Mostrar as previsões\n",
    "print('\\nExibindo as Previsões (versão 1.2):')\n",
    "predictions_v1_2.select(\"Text\", \"Sentiment_Value\", \"prediction\").show(4)\n",
    "\n",
    "# Avaliador para classificação (Acurácia)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Sentiment_Value\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy_v1_2 = evaluator.evaluate(predictions_v1_2)\n",
    "print(f\"\\nAcurácia do modelo Regressão Logística (versão 1.2): {accuracy_v1_2:.2f}\")\n",
    "\n",
    "# Avaliador para classificação (F1-Score)\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"Sentiment_Value\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1_score_v1_2 = f1_evaluator.evaluate(predictions_v1_2)\n",
    "print(f\"\\nF1-Score do modelo Regressão Logística (versão 1.2): {f1_score_v1_2:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46bd322f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+----------+\n",
      "|                Text|Sentiment_Value|prediction|\n",
      "+--------------------+---------------+----------+\n",
      "|' analysts eran s...|              1|       1.0|\n",
      "|'according inform...|              1|       0.0|\n",
      "|'s chatgpt amp ai...|              1|       1.0|\n",
      "|'s first day heme...|              0|       0.0|\n",
      "|'s future video c...|              1|       1.0|\n",
      "|          's opinion|              0|       0.0|\n",
      "|'s powerful effic...|              1|       1.0|\n",
      "|0 invented aaryab...|              1|       1.0|\n",
      "|      0daying living|              0|       0.0|\n",
      "|1 bitcoin ask cha...|              1|       1.0|\n",
      "|1 chatgpt help co...|              1|       1.0|\n",
      "|1 exciting new de...|              1|       1.0|\n",
      "|1 finally got aro...|              1|       1.0|\n",
      "|1 generate code c...|              1|       1.0|\n",
      "|1 law accessibili...|              0|       0.0|\n",
      "|1 monday musings ...|              1|       1.0|\n",
      "|1 using chatgpt w...|              2|       0.0|\n",
      "|10 best practices...|              1|       1.0|\n",
      "|10 components nee...|              1|       1.0|\n",
      "|10 things chatgpt...|              0|       0.0|\n",
      "|10 ways blockchai...|              1|       1.0|\n",
      "|10 ways blockchai...|              0|       0.0|\n",
      "|10 ways blockchai...|              0|       0.0|\n",
      "|10 ways blockchai...|              0|       0.0|\n",
      "|10 ways blockchai...|              0|       0.0|\n",
      "|10 ways developer...|              0|       0.0|\n",
      "|10 ways use chatg...|              0|       0.0|\n",
      "|10 years i'd surp...|              1|       1.0|\n",
      "|10 yo bimbo falle...|              1|       1.0|\n",
      "|100 composed chatgpt|              0|       0.0|\n",
      "+--------------------+---------------+----------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_v1_2.select(\"Text\", \"Sentiment_Value\", \"prediction\").show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "164de7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Acurácia</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regressão Logística</td>\n",
       "      <td>0.715157</td>\n",
       "      <td>0.715118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Regressão Logística (com conf de hiperparametros)</td>\n",
       "      <td>0.796510</td>\n",
       "      <td>0.796552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Modelo  Acurácia  F1-Score\n",
       "0                                Regressão Logística  0.715157  0.715118\n",
       "1  Regressão Logística (com conf de hiperparametros)  0.796510  0.796552"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Salvar as métricas no dataframe df_modelos\n",
    "df_modelos = df_modelos.append({\n",
    "    \"Modelo\": \"Regressão Logística (com conf de hiperparametros)\",\n",
    "    \"Acurácia\": accuracy_v1_2,\n",
    "    \"F1-Score\": f1_score_v1_2\n",
    "}, ignore_index=True)\n",
    "\n",
    "# Exibir o dataframe com as métricas\n",
    "display(df_modelos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56de22a5",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# 2. Árvore de Decisão\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5009c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Acurácia do modelo Árvore de Decisão: 0.47\n",
      "\n",
      "F1-Score do modelo Árvore de Decisão: 0.37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Criar o modelo de Árvore de Decisão\n",
    "dt = DecisionTreeClassifier(featuresCol='scaledFeatures', labelCol='Sentiment_Value')\n",
    "\n",
    "# Treinar o modelo com os dados de treino\n",
    "dt_model = dt.fit(train_data)\n",
    "\n",
    "# Previsões nos dados de teste\n",
    "dt_predictions = dt_model.transform(test_data)\n",
    "\n",
    "# Avaliador para classificação (Acurácia)\n",
    "dt_accuracy = evaluator.evaluate(dt_predictions)\n",
    "print(f\"\\nAcurácia do modelo Árvore de Decisão: {dt_accuracy:.2f}\")\n",
    "\n",
    "# Avaliador para classificação (F1-Score)\n",
    "dt_f1_score = f1_evaluator.evaluate(dt_predictions)\n",
    "print(f\"\\nF1-Score do modelo Árvore de Decisão: {dt_f1_score:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9bf8f441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Acurácia</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regressão Logística</td>\n",
       "      <td>0.715157</td>\n",
       "      <td>0.715118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Regressão Logística (com conf de hiperparametros)</td>\n",
       "      <td>0.796510</td>\n",
       "      <td>0.796552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Árvore de Decisão</td>\n",
       "      <td>0.469413</td>\n",
       "      <td>0.371971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Modelo  Acurácia  F1-Score\n",
       "0                                Regressão Logística  0.715157  0.715118\n",
       "1  Regressão Logística (com conf de hiperparametros)  0.796510  0.796552\n",
       "2                                  Árvore de Decisão  0.469413  0.371971"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Salvar as métricas no dataframe df_modelos\n",
    "df_modelos = df_modelos.append({\n",
    "    \"Modelo\": \"Árvore de Decisão\",\n",
    "    \"Acurácia\": dt_accuracy,\n",
    "    \"F1-Score\": dt_f1_score\n",
    "}, ignore_index=True)\n",
    "\n",
    "# Exibir o dataframe com as métricas\n",
    "display(df_modelos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc735a28",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# 3. Random Forest\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d88463a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Acurácia do modelo Random Forest: 0.47\n",
      "\n",
      "F1-Score do modelo Random Forest: 0.39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Criar o modelo de Random Forest\n",
    "rf = RandomForestClassifier(featuresCol='scaledFeatures', labelCol='Sentiment_Value', numTrees=10)\n",
    "\n",
    "# Treinar o modelo com os dados de treino\n",
    "rf_model = rf.fit(train_data)\n",
    "\n",
    "# Previsões nos dados de teste\n",
    "rf_predictions = rf_model.transform(test_data)\n",
    "\n",
    "# Avaliador para classificação (Acurácia)\n",
    "rf_accuracy = evaluator.evaluate(rf_predictions)\n",
    "print(f\"\\nAcurácia do modelo Random Forest: {rf_accuracy:.2f}\")\n",
    "\n",
    "# Avaliador para classificação (F1-Score)\n",
    "rf_f1_score = f1_evaluator.evaluate(rf_predictions)\n",
    "print(f\"\\nF1-Score do modelo Random Forest: {rf_f1_score:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c2bcbbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Acurácia</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regressão Logística</td>\n",
       "      <td>0.715157</td>\n",
       "      <td>0.715118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Regressão Logística (com conf de hiperparametros)</td>\n",
       "      <td>0.796510</td>\n",
       "      <td>0.796552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Árvore de Decisão</td>\n",
       "      <td>0.469413</td>\n",
       "      <td>0.371971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.473828</td>\n",
       "      <td>0.390337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Modelo  Acurácia  F1-Score\n",
       "0                                Regressão Logística  0.715157  0.715118\n",
       "1  Regressão Logística (com conf de hiperparametros)  0.796510  0.796552\n",
       "2                                  Árvore de Decisão  0.469413  0.371971\n",
       "3                                      Random Forest  0.473828  0.390337"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Salvar as métricas no dataframe df_modelos\n",
    "df_modelos = df_modelos.append({\n",
    "    \"Modelo\": \"Random Forest\",\n",
    "    \"Acurácia\": rf_accuracy,\n",
    "    \"F1-Score\": rf_f1_score\n",
    "}, ignore_index=True)\n",
    "\n",
    "# Exibir o dataframe com as métricas\n",
    "display(df_modelos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2c6f19",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# 4. Naive Bayes \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a8527eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Acurácia do modelo Naive Bayes: 0.65\n",
      "\n",
      "F1-Score do modelo Naive Bayes: 0.65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Criar o modelo de Naive Bayes\n",
    "nb = NaiveBayes(featuresCol='scaledFeatures', labelCol='Sentiment_Value')\n",
    "\n",
    "# Treinar o modelo com os dados de treino\n",
    "nb_model = nb.fit(train_data)\n",
    "\n",
    "# Previsões nos dados de teste\n",
    "nb_predictions = nb_model.transform(test_data)\n",
    "\n",
    "# Avaliador para classificação (Acurácia)\n",
    "nb_accuracy = evaluator.evaluate(nb_predictions)\n",
    "print(f\"\\nAcurácia do modelo Naive Bayes: {nb_accuracy:.2f}\")\n",
    "\n",
    "# Avaliador para classificação (F1-Score)\n",
    "nb_f1_score = f1_evaluator.evaluate(nb_predictions)\n",
    "print(f\"\\nF1-Score do modelo Naive Bayes: {nb_f1_score:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e693feed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Acurácia</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regressão Logística</td>\n",
       "      <td>0.715157</td>\n",
       "      <td>0.715118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Regressão Logística (com conf de hiperparametros)</td>\n",
       "      <td>0.796510</td>\n",
       "      <td>0.796552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Árvore de Decisão</td>\n",
       "      <td>0.469413</td>\n",
       "      <td>0.371971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.473828</td>\n",
       "      <td>0.390337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.649779</td>\n",
       "      <td>0.646901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Modelo  Acurácia  F1-Score\n",
       "0                                Regressão Logística  0.715157  0.715118\n",
       "1  Regressão Logística (com conf de hiperparametros)  0.796510  0.796552\n",
       "2                                  Árvore de Decisão  0.469413  0.371971\n",
       "3                                      Random Forest  0.473828  0.390337\n",
       "4                                        Naive Bayes  0.649779  0.646901"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Salvar as métricas no dataframe df_modelos\n",
    "df_modelos = df_modelos.append({\n",
    "    \"Modelo\": \"Naive Bayes\",\n",
    "    \"Acurácia\": nb_accuracy,\n",
    "    \"F1-Score\": nb_f1_score\n",
    "}, ignore_index=True)\n",
    "\n",
    "# Exibir o dataframe com as métricas\n",
    "display(df_modelos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b989b843",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "# <span style=\"color: green; font-size: 34px; font-weight: bold;\">5. Salvando o Melhor Modelo:</span>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "### Salvando no Pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39387766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo de Regressão Logística versão 1.2 salvo com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Salvar o modelo de Regressão Logística versão 1.2 no disco\n",
    "model_path = \"logistic_regression_model\"\n",
    "lr_model_v1_2.write().overwrite().save(model_path)\n",
    "\n",
    "print(\"Modelo de Regressão Logística versão 1.2 salvo com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257fc388",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>\n",
    "\n",
    "# <span style=\"color: blue; font-size: 44px; font-weight: bold;\">3. Testando o Modelo com Novos Dados com o Pipeline</span>\n",
    "\n",
    "<br><br><br><br><br>\n",
    "\n",
    "# <span style=\"color: green; font-size: 34px; font-weight: bold;\">1. Carregando ou Criando Novos Dados</span>\n",
    "\n",
    "<br>\n",
    "\n",
    "- Os novos dados criados ou carregados tem que ter **obrigatoriamente** as colunas `Text` e `Language`\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Carregando Novos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4061382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " <class 'pyspark.sql.dataframe.DataFrame'> \n",
      "\n",
      "Número de Registros:  30 \n",
      "\n",
      "+--------+--------+--------------------+--------+---------+----+--------+----------+----------+------------+---------+----------+--------------+--------+------+-----+-----------+--------------+-------+-------------+\n",
      "|Datetime|Tweet Id|                Text|Username|Permalink|User|Outlinks|CountLinks|ReplyCount|RetweetCount|LikeCount|QuoteCount|ConversationId|Language|Source|Media|QuotedTweet|MentionedUsers|hashtag|hastag_counts|\n",
      "+--------+--------+--------------------+--------+---------+----+--------+----------+----------+------------+---------+----------+--------------+--------+------+-----+-----------+--------------+-------+-------------+\n",
      "|    NULL|    NULL|ChatGPT is just r...|    NULL|     NULL|NULL|    NULL|      NULL|      NULL|        NULL|     NULL|      NULL|          NULL|      en|  NULL| NULL|       NULL|          NULL|   NULL|         NULL|\n",
      "|    NULL|    NULL|Tried using ChatG...|    NULL|     NULL|NULL|    NULL|      NULL|      NULL|        NULL|     NULL|      NULL|          NULL|      en|  NULL| NULL|       NULL|          NULL|   NULL|         NULL|\n",
      "|    NULL|    NULL|ChatGPT can't und...|    NULL|     NULL|NULL|    NULL|      NULL|      NULL|        NULL|     NULL|      NULL|          NULL|      en|  NULL| NULL|       NULL|          NULL|   NULL|         NULL|\n",
      "|    NULL|    NULL|The responses fro...|    NULL|     NULL|NULL|    NULL|      NULL|      NULL|        NULL|     NULL|      NULL|          NULL|      en|  NULL| NULL|       NULL|          NULL|   NULL|         NULL|\n",
      "|    NULL|    NULL|Why does ChatGPT ...|    NULL|     NULL|NULL|    NULL|      NULL|      NULL|        NULL|     NULL|      NULL|          NULL|      en|  NULL| NULL|       NULL|          NULL|   NULL|         NULL|\n",
      "+--------+--------+--------------------+--------+---------+----+--------+----------+----------+------------+---------+----------+--------------+--------+------+-----+-----------+--------------+-------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Carrega os dados\n",
    "new_data = spark.read.csv('dados/new_data_chatgpt.csv', inferSchema = True, header = True)\n",
    "\n",
    "print('\\n', type(new_data), '\\n')\n",
    "\n",
    "# Número de registros\n",
    "print('Número de Registros: ', new_data.count(), '\\n')\n",
    "\n",
    "# Visualiza os dados no padrão do Spark DataFrame\n",
    "new_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de31b10",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# <span style=\"color: green; font-size: 34px; font-weight: bold;\">2. Aplicando Pipelines de Transformações</span>\n",
    "\n",
    "<br>\n",
    "\n",
    "### Criando e Salvando Pipeline de Transformação de Novos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4d8c4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline salvo com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Função para limpar o texto\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)      # Remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text)         # Remove menções (@usuário)\n",
    "    text = re.sub(r'#\\w+', '', text)         # Remove hashtags (#)\n",
    "    text = re.sub(r'[^\\w\\s\\']', '', text)    # Remove emojis e pontuações, exceto apóstrofos\n",
    "    text = re.sub(r'\\s+', ' ', text)         # Remove múltiplos espaços\n",
    "    text = text.replace('_', ' ')            # Remove underlines manualmente\n",
    "    text = text.lower().strip()              # Converte para minúsculas e remove espaços extras\n",
    "    return text\n",
    "\n",
    "# Função para remover stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_text = ' '.join([word for word in words if word not in stop_words])\n",
    "    return filtered_text\n",
    "\n",
    "# Converter as funções para UDFs\n",
    "clean_text_udf = udf(lambda text: clean_text(text), StringType())\n",
    "remove_stopwords_udf = udf(lambda text: remove_stopwords(text), StringType())\n",
    "\n",
    "# Aplicar a função de filtragem por idioma com SQLTransformer\n",
    "language_filter = SQLTransformer(statement=\"SELECT * FROM __THIS__ WHERE Language = 'en'\")\n",
    "\n",
    "# Criar transformadores customizados herdando de `Transformer`\n",
    "class CleanTextStage(Transformer, DefaultParamsReadable, DefaultParamsWritable):\n",
    "    def _transform(self, df):\n",
    "        # Aplicar a função de limpeza\n",
    "        df = df.withColumn(\"cleaned_text\", clean_text_udf(col(\"Text\")))\n",
    "        return df\n",
    "\n",
    "class RemoveStopwordsStage(Transformer, DefaultParamsReadable, DefaultParamsWritable):\n",
    "    def _transform(self, df):\n",
    "        # Aplicar a função de remoção de stopwords\n",
    "        df = df.withColumn(\"final_text\", remove_stopwords_udf(col(\"cleaned_text\")))\n",
    "        return df\n",
    "\n",
    "# Adicionar um SQLTransformer para renomear 'final_text' para 'Text'\n",
    "rename_column_stage = SQLTransformer(statement=\"SELECT final_text AS Text FROM __THIS__\")\n",
    "\n",
    "# Pipeline com todas as etapas, incluindo transformações customizadas e renomeação\n",
    "pipeline = Pipeline(stages=[language_filter, CleanTextStage(), RemoveStopwordsStage(), rename_column_stage])\n",
    "\n",
    "# Ajustar o pipeline nos dados simulados\n",
    "pipeline_model = pipeline.fit(new_data)\n",
    "\n",
    "# Salvar o pipeline ajustado\n",
    "pipeline_model.write().overwrite().save(\"sentiment_preprocessing_pipeline_for_new_data\")\n",
    "\n",
    "print(\"Pipeline salvo com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754cb4f4",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Carregando e Aplicando Pipeline de Transformação de Novos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0190e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------+\n",
      "|Text                                                                   |\n",
      "+-----------------------------------------------------------------------+\n",
      "|chatgpt repeating generic answers impressed                            |\n",
      "|tried using chatgpt kept giving incorrect information what's hype      |\n",
      "|chatgpt can't understand simple questions sometimes frustrating helpful|\n",
      "|responses chatgpt feel robotic lack depth overrated                    |\n",
      "|chatgpt give many irrelevant answers reliable                          |\n",
      "|chatgpt toy tool expected accuracy                                     |\n",
      "|chatgpt completely misunderstood question smart claims                 |\n",
      "|people overhyping chatgpt can't even handle complex questions          |\n",
      "|chatgpt's answers feel generic could google get better info            |\n",
      "|using chatgpt like talking wall real insight fluff                     |\n",
      "|chatgpt decent tasks perfect works well certain cases                  |\n",
      "|sometimes chatgpt gives good answers times misses mark hit miss        |\n",
      "|chatgpt okay still needs improvement understanding complex topics      |\n",
      "|chatgpt helpful rely everything                                        |\n",
      "|chatgpt useful tool also make lot mistakes depends use                 |\n",
      "|chatgpt fine basic queries expect deep insights                        |\n",
      "|good chatgpt brainstorming always accurate                             |\n",
      "|chatgpt helpful tool replace actual human expertise                    |\n",
      "|chatgpt answer questions well useful quick tasks                       |\n",
      "|chatgpt decent tool general info use detailed research                 |\n",
      "+-----------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Carregar o pipeline salvo\n",
    "pipeline_for_new_data = PipelineModel.load(\"sentiment_preprocessing_pipeline_for_new_data\")\n",
    "\n",
    "# Aplicar o pipeline nos novos dados\n",
    "dados_transformados = pipeline_for_new_data.transform(new_data)\n",
    "\n",
    "# Exibir os dados transformados\n",
    "dados_transformados.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca943c2",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Carregando e Aplicando Pipeline de Pré-Processamento de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9a4717d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                Text|               words|         rawFeatures|            features|      scaledFeatures|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|chatgpt repeating...|[chatgpt, repeati...|(10000,[2970,5742...|(10000,[2970,5742...|(10000,[2970,5742...|\n",
      "|tried using chatg...|[tried, using, ch...|(10000,[960,1063,...|(10000,[960,1063,...|(10000,[960,1063,...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicar o pipeline aos novos dados\n",
    "loaded_pipeline = PipelineModel.load(\"sentiment_analysis_pipeline\")\n",
    "dados_pre_ml = loaded_pipeline.transform(dados_transformados)\n",
    "\n",
    "# Exibir os dados transformados\n",
    "dados_pre_ml.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d7a98",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# <span style=\"color: green; font-size: 34px; font-weight: bold;\">3. Carregar o Modelo Salvo</span>\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Carregando Modelo de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52dbbf8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionModel: uid=LogisticRegression_1d2b5f3e654a, numClasses=3, numFeatures=10000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "\n",
    "# Caminho onde o modelo foi salvo\n",
    "model_path = \"logistic_regression_model\"\n",
    "\n",
    "# Carregar o modelo de Regressão Logística salvo\n",
    "loaded_lr_model = LogisticRegressionModel.load(model_path)\n",
    "loaded_lr_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5994c22",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# <span style=\"color: green; font-size: 34px; font-weight: bold;\">4. Aplicar o Modelo de Machine Learning aos Novos Dados</span>\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Aplicando Modelo de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29f6bd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|                Text|               words|         rawFeatures|            features|      scaledFeatures|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|chatgpt repeating...|[chatgpt, repeati...|(10000,[2970,5742...|(10000,[2970,5742...|(10000,[2970,5742...|[0.54851046819901...|[0.19031774329565...|       2.0|\n",
      "|tried using chatg...|[tried, using, ch...|(10000,[960,1063,...|(10000,[960,1063,...|(10000,[960,1063,...|[-0.1593551767196...|[0.36601654672871...|       0.0|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicar o modelo nos dados pré-processados (dados_pre_ml)\n",
    "predictions = loaded_lr_model.transform(dados_pre_ml)\n",
    "predictions.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "104b3f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------+----------+-------------------------------------------------------------+\n",
      "|Text                                                                   |prediction|probability                                                  |\n",
      "+-----------------------------------------------------------------------+----------+-------------------------------------------------------------+\n",
      "|chatgpt repeating generic answers impressed                            |2.0       |[0.1903177432956522,0.16074513682704278,0.6489371198773051]  |\n",
      "|tried using chatgpt kept giving incorrect information what's hype      |0.0       |[0.36601654672871153,0.3237075081151365,0.31027594515615187] |\n",
      "|chatgpt can't understand simple questions sometimes frustrating helpful|2.0       |[0.037840671365661396,0.0748188196308895,0.8873405090034491] |\n",
      "|responses chatgpt feel robotic lack depth overrated                    |2.0       |[0.14418197713764566,0.05978865406986438,0.79602936879249]   |\n",
      "|chatgpt give many irrelevant answers reliable                          |2.0       |[0.11324572603168079,0.059258013443180005,0.8274962605251391]|\n",
      "|chatgpt toy tool expected accuracy                                     |0.0       |[0.5067503502329794,0.28141311445788225,0.21183653530913843] |\n",
      "|chatgpt completely misunderstood question smart claims                 |1.0       |[0.13398672679293697,0.7710361594432569,0.09497711376380621] |\n",
      "|people overhyping chatgpt can't even handle complex questions          |2.0       |[0.2611230386507501,0.12489846773837425,0.6139784936108756]  |\n",
      "|chatgpt's answers feel generic could google get better info            |2.0       |[0.13664887450016755,0.31951083741887226,0.5438402880809601] |\n",
      "|using chatgpt like talking wall real insight fluff                     |1.0       |[0.10089381058428284,0.5845544864997235,0.31455170291599366] |\n",
      "|chatgpt decent tasks perfect works well certain cases                  |1.0       |[0.04044496924581733,0.9206593488545023,0.038895681899680484]|\n",
      "|sometimes chatgpt gives good answers times misses mark hit miss        |2.0       |[0.017548791817823026,0.06769034743916312,0.9147608607430139]|\n",
      "|chatgpt okay still needs improvement understanding complex topics      |2.0       |[0.21115160649055995,0.2554106091200506,0.5334377843893895]  |\n",
      "|chatgpt helpful rely everything                                        |2.0       |[0.26438025341076377,0.23159002235858506,0.5040297242306512] |\n",
      "|chatgpt useful tool also make lot mistakes depends use                 |2.0       |[0.12666242429331126,0.3995264803448442,0.4738110953618444]  |\n",
      "|chatgpt fine basic queries expect deep insights                        |0.0       |[0.3622549492075804,0.3039194982115504,0.3338255525808694]   |\n",
      "|good chatgpt brainstorming always accurate                             |1.0       |[0.16823298037676324,0.4735335582111016,0.3582334614121352]  |\n",
      "|chatgpt helpful tool replace actual human expertise                    |1.0       |[0.27051964977477805,0.4004288034438286,0.3290515467813933]  |\n",
      "|chatgpt answer questions well useful quick tasks                       |1.0       |[0.07559124834563885,0.607638466729316,0.3167702849250452]   |\n",
      "|chatgpt decent tool general info use detailed research                 |0.0       |[0.45374574698178327,0.25197812645113343,0.29427612656708324]|\n",
      "+-----------------------------------------------------------------------+----------+-------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exibir os resultados das previsões\n",
    "predictions.select(\"Text\", \"prediction\", \"probability\").show(truncate=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "35e86c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       1.0|\n",
      "|       2.0|\n",
      "|       0.0|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificar os valores únicos presentes na coluna 'prediction'\n",
    "predictions.select(\"prediction\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "891e1394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8e7af9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+\n",
      "|prediction|prediction_value|\n",
      "+----------+----------------+\n",
      "|2.0       |negativo        |\n",
      "|0.0       |neutro          |\n",
      "|2.0       |negativo        |\n",
      "|2.0       |negativo        |\n",
      "|2.0       |negativo        |\n",
      "|0.0       |neutro          |\n",
      "|1.0       |positivo        |\n",
      "|2.0       |negativo        |\n",
      "|2.0       |negativo        |\n",
      "|1.0       |positivo        |\n",
      "|1.0       |positivo        |\n",
      "|2.0       |negativo        |\n",
      "|2.0       |negativo        |\n",
      "|2.0       |negativo        |\n",
      "|2.0       |negativo        |\n",
      "|0.0       |neutro          |\n",
      "|1.0       |positivo        |\n",
      "|1.0       |positivo        |\n",
      "|1.0       |positivo        |\n",
      "|0.0       |neutro          |\n",
      "+----------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Criar a nova coluna 'prediction_value' com base na coluna 'prediction'\n",
    "predictions = predictions.withColumn(\n",
    "    \"prediction_value\", \n",
    "    F.when(F.col(\"prediction\") == 1.0, \"positivo\")\n",
    "    .when(F.col(\"prediction\") == 2.0, \"negativo\")\n",
    "    .when(F.col(\"prediction\") == 0.0, \"neutro\")\n",
    "    .otherwise(\"desconhecido\")  # Caso haja outro valor que não esteja entre 0, 1 ou 2\n",
    ")\n",
    "\n",
    "# Mostrar os resultados para verificar a nova coluna\n",
    "predictions.select(\"prediction\", \"prediction_value\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ae5b64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------+----------------+\n",
      "|Text                                                                   |prediction_value|\n",
      "+-----------------------------------------------------------------------+----------------+\n",
      "|chatgpt repeating generic answers impressed                            |negativo        |\n",
      "|tried using chatgpt kept giving incorrect information what's hype      |neutro          |\n",
      "|chatgpt can't understand simple questions sometimes frustrating helpful|negativo        |\n",
      "|responses chatgpt feel robotic lack depth overrated                    |negativo        |\n",
      "|chatgpt give many irrelevant answers reliable                          |negativo        |\n",
      "|chatgpt toy tool expected accuracy                                     |neutro          |\n",
      "|chatgpt completely misunderstood question smart claims                 |positivo        |\n",
      "|people overhyping chatgpt can't even handle complex questions          |negativo        |\n",
      "|chatgpt's answers feel generic could google get better info            |negativo        |\n",
      "|using chatgpt like talking wall real insight fluff                     |positivo        |\n",
      "|chatgpt decent tasks perfect works well certain cases                  |positivo        |\n",
      "|sometimes chatgpt gives good answers times misses mark hit miss        |negativo        |\n",
      "|chatgpt okay still needs improvement understanding complex topics      |negativo        |\n",
      "|chatgpt helpful rely everything                                        |negativo        |\n",
      "|chatgpt useful tool also make lot mistakes depends use                 |negativo        |\n",
      "|chatgpt fine basic queries expect deep insights                        |neutro          |\n",
      "|good chatgpt brainstorming always accurate                             |positivo        |\n",
      "|chatgpt helpful tool replace actual human expertise                    |positivo        |\n",
      "|chatgpt answer questions well useful quick tasks                       |positivo        |\n",
      "|chatgpt decent tool general info use detailed research                 |neutro          |\n",
      "+-----------------------------------------------------------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exibir os resultados das previsões\n",
    "predictions.select(\"Text\", \"prediction_value\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22192b1",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>\n",
    "\n",
    "# <span style=\"color: blue; font-size: 44px; font-weight: bold;\">3. Testando o Modelo com Interface Gráfica</span>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "### Criando e Visualizando a Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc556f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2b8b39f85745298019f7f6b74ea615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Textarea(value='', layout=Layout(height='100px', margin='20px auto', width='60%'), placeholder=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import col, udf\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "\n",
    "# Inicializar SparkSession\n",
    "spark = SparkSession.builder.appName(\"ChatGPT Sentiment Analysis\").getOrCreate()\n",
    "\n",
    "# Funções de processamento de texto\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s\\']', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.replace('_', ' ')\n",
    "    text = text.lower().strip()\n",
    "    return text\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_text = ' '.join([word for word in words if word not in stop_words])\n",
    "    return filtered_text\n",
    "\n",
    "# Funções UDF para PySpark\n",
    "clean_text_udf = udf(lambda text: clean_text(text), StringType())\n",
    "remove_stopwords_udf = udf(lambda text: remove_stopwords(text), StringType())\n",
    "\n",
    "# Widgets centralizados e espaçados adequadamente\n",
    "text_input = widgets.Textarea(\n",
    "    placeholder='Digite o texto (máximo 500 caracteres)', \n",
    "    layout=widgets.Layout(width=\"60%\", height=\"100px\", margin='20px auto')\n",
    ")\n",
    "language_select = widgets.Dropdown(\n",
    "    options=[('English', 'en'), ('Português', 'pt-br'), ('Spanish', 'sp')], \n",
    "    value='en', \n",
    "    description='Idioma:',\n",
    "    layout=widgets.Layout(width='30%', margin='10px auto')\n",
    ")\n",
    "button_verificar = widgets.Button(\n",
    "    description=\"Verificar\", \n",
    "    button_style='success', \n",
    "    layout=widgets.Layout(width='150px', margin='20px auto')\n",
    ")\n",
    "output_result = widgets.Output(layout=widgets.Layout(margin='20px auto', width='60%'))\n",
    "button_sim = widgets.Button(\n",
    "    description=\"Sim\", \n",
    "    button_style='success', \n",
    "    layout=widgets.Layout(width='100px', margin='20px auto', display='flex', justify_content='center')\n",
    ")\n",
    "button_nao = widgets.Button(\n",
    "    description=\"Não\", \n",
    "    button_style='danger', \n",
    "    layout=widgets.Layout(width='100px', margin='20px auto', display='flex', justify_content='center')\n",
    ")\n",
    "\n",
    "# Função para verificar o texto\n",
    "def verificar_texto(b):\n",
    "    with output_result:\n",
    "        clear_output()\n",
    "        input_text = text_input.value.strip()\n",
    "        \n",
    "        if len(input_text) < 10 or language_select.value != 'en':\n",
    "            print(\"Erro: O texto deve ter no mínimo 10 caracteres e o idioma deve ser 'en'.\")\n",
    "            return\n",
    "        \n",
    "        new_data = spark.createDataFrame([(input_text,)], [\"Text\"])\n",
    "        new_data = new_data.withColumn(\"Language\", F.lit(\"en\"))\n",
    "        \n",
    "        new_data = new_data.withColumn(\"cleaned_text\", clean_text_udf(col(\"Text\")))\n",
    "        new_data = new_data.withColumn(\"final_text\", remove_stopwords_udf(col(\"cleaned_text\")))\n",
    "        new_data = new_data.select(F.col(\"final_text\").alias(\"Text\"), \"Language\")\n",
    "        \n",
    "        # Carregar e aplicar o pipeline de análise de sentimentos\n",
    "        loaded_pipeline = PipelineModel.load(\"sentiment_analysis_pipeline\")\n",
    "        new_data = loaded_pipeline.transform(new_data)\n",
    "        \n",
    "        # Carregar o modelo de Machine Learning\n",
    "        loaded_lr_model = LogisticRegressionModel.load(\"logistic_regression_model\")\n",
    "        predictions = loaded_lr_model.transform(new_data)\n",
    "\n",
    "        # Criar coluna de 'prediction_value' para exibir o resultado\n",
    "        predictions = predictions.withColumn(\n",
    "            \"prediction_value\", \n",
    "            F.when(F.col(\"prediction\") == 1.0, \"positivo\")\n",
    "            .when(F.col(\"prediction\") == 2.0, \"negativo\")\n",
    "            .when(F.col(\"prediction\") == 0.0, \"neutro\")\n",
    "            .otherwise(\"desconhecido\")\n",
    "        )\n",
    "\n",
    "        # Mostrar o resultado para o usuário com o \"Sentimento\" em negrito e centralizado\n",
    "        sentimento = predictions.select('prediction_value').collect()[0][0]\n",
    "        display(HTML(f\"<div style='text-align: center;'><b>Texto:</b> {input_text}</div>\"))\n",
    "        display(HTML(f\"<div style='text-align: center;'><b>Sentimento:</b> <span style='color:black;'><u>{sentimento}</u></span></div>\"))\n",
    "        \n",
    "        # Mostrar botões 'Sim' e 'Não'\n",
    "        display(widgets.HBox([button_sim, button_nao], layout=widgets.Layout(justify_content='center')))\n",
    "\n",
    "# Função para resetar o texto e ocultar botões\n",
    "def reset(b):\n",
    "    text_input.value = \"\"\n",
    "    clear_output()\n",
    "\n",
    "# Função para fechar a interface\n",
    "def close_interface(b):\n",
    "    clear_output()\n",
    "    display(HTML(\"<b>Interface finalizada.</b>\"))\n",
    "\n",
    "# Atribuir as funções aos botões\n",
    "button_verificar.on_click(verificar_texto)\n",
    "button_sim.on_click(reset)\n",
    "button_nao.on_click(close_interface)\n",
    "\n",
    "# Exibir os widgets centralizados\n",
    "display(widgets.VBox([text_input, language_select, button_verificar, output_result], layout=widgets.Layout(align_items='center')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265a4f78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4187d697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8041fcd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d74800a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54642932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278d0f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb0a7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf52336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8abbca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0f1750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f527c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2c02b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc32f7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5794a81f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2902ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9542a878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b01010f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f4de9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9827b1f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4d245c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23152682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d71226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5def0e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6ad1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9945802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b4bc17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc23e889",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
